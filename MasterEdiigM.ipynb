{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b0dcc2-b660-4797-958c-fecce2e085f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\samil\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\envs\\samil\\lib\\site-packages\\numpy\\.libs\\libopenblas.gk7gx5keq4f6uyo3p26ulgbqyhgqo7j4.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\envs\\samil\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###row index not found D:\\Automation\\OutputW\\Ediig\\Ediig\\Ediig2024-07-24_13-57\\1721797163964_24-25-JUL-MANAPPURAM-AP-2W.xls\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['Agreement Number*'] ['Agreement Number*']\n",
      "Found Keywords: ### ['Agreement Number*'] ['Agreement Number*']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['Loan No.'] ['Loan No.']\n",
      "Found Keywords: ### ['Agreement Number*'] ['Agreement Number*']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['Loan No.'] ['Loan No.']\n",
      "Found Keywords: ### ['Agreement Number*'] ['Agreement Number*']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['AGREEMENTID'] ['AGREEMENTID']\n",
      "Found Keywords: ### ['Loan No.'] ['Loan No.']\n",
      "Found Keywords: ### ['CONTRACTNUMBER'] ['CONTRACTNUMBER']\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#from sklearn.model_selection import RandomizedSearchCVa\n",
    "pd.set_option('display.float_format', lambda x: '%0.3f' % x)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',1000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "sheet1 = pd.read_excel(\"D://Automation//Scripts//final_verticle_file.xlsb\",sheet_name = 'Ediig_Verticle')\n",
    "sheet1['Ediig']=sheet1['Ediig'].str.strip()\n",
    "sheet1['FinalVertical']=sheet1['FinalVertical'].str.strip()\n",
    "\n",
    "\n",
    "# Define the data as a dictionary\n",
    "state_df = {\n",
    "    'State_': [\n",
    "        'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chhattisgarh',\n",
    "        'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jammu and Kashmir',\n",
    "        'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra',\n",
    "        'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Orissa',\n",
    "        'Punjab', 'Rajasthan', 'Sikkim', 'Telangana', 'Tripura', 'Uttarakhand',\n",
    "        'Uttar Pradesh', 'West Bengal', 'Tamil Nadu', 'Tripura', 'Andaman and Nicobar Islands',\n",
    "        'Chandigarh', 'Dadra and Nagar Haveli', 'Daman and Diu', 'Delhi',\n",
    "        'Lakshadweep', 'Pondicherry','East','West','North','South','Delhi'\n",
    "    ],\n",
    "    'Abbreviation': [\n",
    "        'AP', 'AR', 'AS', 'BR', 'CG',\n",
    "        'GA', 'GJ', 'HR', 'HP', 'JK',\n",
    "        'JH', 'KA', 'KL', 'MP', 'MH',\n",
    "        'MN', 'ML', 'MZ', 'NL', 'OR',\n",
    "        'PB', 'RJ', 'SK', 'TS', 'TR', 'UK',\n",
    "        'UP', 'WB', 'TN', 'TR', 'AN', 'CH',\n",
    "        'DH', 'DD', 'DL', 'LD', 'PY','East','West','North','South','Delhi'\n",
    "    ],\n",
    "    'Region_': [\n",
    "        'South', 'East', 'East', 'East', 'West',\n",
    "        'West', 'West', 'North', 'North', 'North',\n",
    "        'East', 'South', 'South', 'West', 'West',\n",
    "        'East', 'East', 'East', 'East', 'East',\n",
    "        'North', 'North', 'East', 'South', 'East',\n",
    "        'North', 'North', 'West', 'South', 'East', 'South',\n",
    "        'North', 'West', 'West', 'North', 'South', 'South','East','West','North','South','North'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_state = pd.DataFrame(state_df)\n",
    "\n",
    "def is_valid_alphanumeric(value):\n",
    "    return bool(re.match(r'^[A-Za-z0-9]+$', str(value)))\n",
    "os.chdir(f\"D:\\\\Automation\\\\OutputW\\\\Ediig\\\\\")\n",
    "folder_path = f\"D:\\\\Automation\\\\OutputW\\\\Ediig\\\\\"\n",
    "excel_files_list = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(folder_path)\n",
    "    for file in files\n",
    "    if (file.endswith(\".xlsx\") or file.endswith(\".xls\"))\n",
    "]\n",
    "data = []\n",
    "try:\n",
    "    for file in excel_files_list:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_excel(file_path,header=None)\n",
    "            #print('#####',file_path)\n",
    "        except:\n",
    "            print('Issue in file please check',file_path) #AGRNO  Contract No\n",
    "\n",
    "\n",
    "        keywords_to_find = ['Contract Number','Agreement Number','AgreementNo','LOS','HP NO.','Loan No','Loan No.', 'Contract No.',\n",
    "                            'Contract No / Loan No','Agreement No.','Agreement Number*','Deal No','AGRNO','Loan Account #',      \n",
    "                            'KOTAK Agmt. No.','Contract No','Loan Agreement No','LAN','Loan Number','CONTRACTNUMBER',\n",
    "                            'Agreement No.','AGREEMENTID']#AGRNO\n",
    "\n",
    "\n",
    "        found_keywords = []\n",
    "        try:\n",
    "            for column in df.columns:\n",
    "                for keyword in keywords_to_find:\n",
    "                    if keyword in df[column].values:\n",
    "                        found_keywords.append(keyword)\n",
    "                        final_found_word = set(found_keywords)\n",
    "                        final_found_words = list(final_found_word)\n",
    "                        #print('keywords found',final_found_words,file_path)\n",
    "                        print(\"Found Keywords:\", '###',final_found_words, found_keywords)\n",
    "        except:\n",
    "            print('keywords not found ')\n",
    "        try:\n",
    "\n",
    "\n",
    "            row_index, col_index = [(i, j) for i, row in df.iterrows() for j, cell in enumerate(row) if cell in final_found_words], [(j, i) for i, col in df.items() for j, cell in enumerate(col) if cell in final_found_words]\n",
    "            \n",
    "        except:\n",
    "            print('###row index not found',file)\n",
    "            \n",
    "\n",
    "        try:\n",
    "            if (len(found_keywords)== 1):\n",
    "                #print(count3)\n",
    "                #print(f\"Row Index: {row_index[0]}, Column Index: {col_index[0]}\")\n",
    "                df1= df.iloc[row_index[0][0]:,[row_index[0][1]]].values\n",
    "\n",
    "                df2 = pd.DataFrame(df1)\n",
    "                df2.columns = df2.iloc[0]\n",
    "                df2 = df2[1:]\n",
    "                df2 = df2.reset_index(drop=True)\n",
    "                #df2.columns = df2.columns.str.replace(r'^\\d+\\s+', '', regex=True)\n",
    "                #print(df2)df.rename(columns=lambda x: x.lstrip('0 '), inplace=True)\n",
    "                df2.dropna(inplace = True)\n",
    "\n",
    "                df_final1 = df2[df2[df2.columns[0]].apply(lambda x: is_valid_alphanumeric(x) and (not (str(x).isdigit() and len(str(x)) < 5)))]\n",
    "                #print(df_final1.columns)\n",
    "                for i in df_final1.values:\n",
    "                    lan_no = i[0]\n",
    "                    #print('lan no1',lan_no,file)\n",
    "                    #file_path = os.path.join(folder_path, file)\n",
    "                    file_name = file_path.split('/')[-1].split('-')\n",
    "\n",
    "\n",
    "                    # logic of location and state\n",
    "                    location = file_name[-1].strip().split('.')[0] # location state\n",
    "                    final_location = location.title()\n",
    "\n",
    "                    Client_name = file_path.split('/')[-1].split('-')[-2] # client\n",
    "                    final_client_name = Client_name.title()\n",
    "                    try:\n",
    "                        demo = Client_name + '-' + location + '.xls'\n",
    "                    except:\n",
    "                        demo = Client_name + '-' + location + '.xlsx'\n",
    "\n",
    "                    company_name = 'Ediig'# company name\n",
    "\n",
    "                    # Logic of month\n",
    "                    current_date = datetime.now()\n",
    "                    formatted_date = current_date.strftime(\"%d-%b-%Y\") # month\n",
    "\n",
    "\n",
    "                    # logic of make and product\n",
    "                    try:\n",
    "                        category = file_path.split('/')[-1].split(\"ET\")[1].strip()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    result_2 = category.replace(demo, \"\").strip()\n",
    "                    #print(category,'#####', demo,'@@@@',result_2)\n",
    "                    make = result_2[1:-1] if result_2.startswith(\"-\") and result_2.endswith(\"-\") else result_2.lstrip(\"-\").rstrip(\"-\") # make and product\n",
    "\n",
    "                    auction_type = \"Online\"  #auction type\n",
    "\n",
    "                    # Logic of auction date\n",
    "                    try:\n",
    "                        auction_date = file_name[1] +'-' + file_name[2] + '-' + str((datetime.now().year)% 100)\n",
    "                    except:\n",
    "                        auction_date = file_name[1] + '-' + str((datetime.now().year)% 100)\n",
    "                    data.append({'Make':make,'Product':make,'Lan No':lan_no,'Client':final_client_name,'Comp Name':'Ediig','Location':final_location,'State':final_location,'Region':'nan','Auction Date': auction_date,'Auction Type':'Online','Verticle':'nan','Month':formatted_date})\n",
    "\n",
    "            elif (len(found_keywords)== 2):\n",
    "                # for first occurence \n",
    "                df11= df.iloc[row_index[0][0]:,[row_index[0][1]]]\n",
    "                df11=df11.reset_index(drop = True)\n",
    "                df11.columns = df11.iloc[0]\n",
    "                df11 = df11[1:]\n",
    "                #df1.dropna(inplace = True)\n",
    "                df11=df11.reset_index(drop = True)\n",
    "                try:\n",
    "                    nan_index = df11.index[df11[df11.columns[0]].isna()].tolist()[0]\n",
    "                    df11_cleaned = df11.iloc[:nan_index]\n",
    "\n",
    "                except:\n",
    "                    print('file issue2')\n",
    "\n",
    "                # for second occurence\n",
    "                try:\n",
    "                    df22= df.iloc[row_index[1][0]:,[row_index[1][1]]]\n",
    "                    df22=df22.reset_index(drop = True)\n",
    "                    df22.columns = df22.iloc[0]\n",
    "                    df22 = df22[1:]\n",
    "                    df22=df22.reset_index(drop = True)\n",
    "                except:\n",
    "                    print('file issue2')\n",
    "                # combine dataframe\n",
    "                try:\n",
    "                    combined_df = pd.concat([df11_cleaned,df22], ignore_index = True)\n",
    "                    df_final1 = combined_df[combined_df[combined_df.columns[0]].apply(lambda x: is_valid_alphanumeric(x) and (not (str(x).isdigit() and len(str(x)) < 5)))]\n",
    "                #print(df_final1.columns)\n",
    "                except:\n",
    "                    print('file issue3')\n",
    "                for i in df_final1.values:\n",
    "                    lan_no = i[0]\n",
    "                    #print('lan no2',lan_no,file)\n",
    "\n",
    "                    #file_path = os.path.join(folder_path, file)\n",
    "                    file_name = file_path.split('/')[-1].split('-')\n",
    "\n",
    "\n",
    "                    # logic of location and state\n",
    "                    location = file_name[-1].strip().split('.')[0] # location state\n",
    "                    final_location = location.title()\n",
    "                    #final_location = location.title()\n",
    "                    #print(final_location)\n",
    "                    Client_name = file_path.split('/')[-1].split('-')[-2] # client\n",
    "                    final_client_name = Client_name.title()\n",
    "                    try:\n",
    "                        demo = Client_name + '-' + location + '.xls'\n",
    "                    except:\n",
    "                        demo = Client_name + '-' + location + '.xlsx'\n",
    "\n",
    "                    company_name = 'Ediig'# company name\n",
    "\n",
    "                    # Logic of month\n",
    "                    current_date = datetime.now()\n",
    "                    formatted_date = current_date.strftime(\"%d-%b-%Y\") # month\n",
    "\n",
    "\n",
    "                    # logic of make and product\n",
    "                    try:\n",
    "                        category = file_path.split('/')[-1].split(\"ET\")[1].strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    result_2 = category.replace(demo, \"\").strip()\n",
    "                    make = result_2[1:-1] if result_2.startswith(\"-\") and result_2.endswith(\"-\") else result_2.lstrip(\"-\").rstrip(\"-\") # make and product\n",
    "\n",
    "                    auction_type = \"Online\"  #auction type\n",
    "\n",
    "                    # Logic of auction date\n",
    "                    try:\n",
    "                        auction_date = file_name[1] +'-' + file_name[2] + '-' + str((datetime.now().year)% 100)\n",
    "                    except:\n",
    "                        auction_date = file_name[1] + '-' + str((datetime.now().year)% 100)\n",
    "                    data.append({'Make':make,'Product':make,'Lan No':lan_no,'Client':final_client_name,'Comp Name':'Ediig','Location':final_location,'State':final_location,'Region':'nan','Auction Date': auction_date,'Auction Type':'Online','Verticle':'nan','Month':formatted_date})\n",
    "        except:\n",
    "            print('issue in keyword length code ')\n",
    "        final_df = pd.DataFrame(data)\n",
    "except:\n",
    "    print('file issue last except')\n",
    "    \n",
    "    \n",
    "#final_df = final_df.dropna(subset=['Lan No'])\n",
    "try:\n",
    "    final_df['Client']=final_df['Client'].str.strip()\n",
    "    final_df['Make'] = final_df['Make'].str.upper()\n",
    "    final_df = final_df[final_df['Make'] != \"SLV\"].reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "    #Region\n",
    "    final_df[\"Make\"] = final_df[\"Make\"].apply(lambda x: x.split('-')[0] if '-' in x else x)\n",
    "\n",
    "    merged_df = pd.merge(final_df,df_state,how = \"left\", left_on = \"State\",right_on = \"State_\")\n",
    "    final_df['Region'] = merged_df['Region_'].combine_first(final_df['Region'])\n",
    "\n",
    "\n",
    "\n",
    "    # Vertical code\n",
    "    merged_df1 = pd.merge(final_df,sheet1, how=\"left\", left_on=\"Client\", right_on=\"Ediig\")\n",
    "    final_df['Verticle'] = merged_df1['FinalVertical'].combine_first(final_df['Verticle'])\n",
    "except:\n",
    "    print(\"issue in verticle and region\")\n",
    "\n",
    "\n",
    "folder_path = 'D://Automation//OutputM//'  # Replace with the desired parent directory path\n",
    "folder_name = 'ediig'  # Replace with the desired folder name\n",
    "\n",
    "# Create the folder\n",
    "full_folder_path = os.path.join(folder_path, folder_name)\n",
    "if not os.path.exists(full_folder_path):\n",
    "    os.makedirs(full_folder_path)\n",
    "final_df.to_csv(os.path.join(full_folder_path, 'masterfile_ediig.csv'), index=False)\n",
    "print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d66acb-b06b-4711-9ca4-686efb9b0b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
